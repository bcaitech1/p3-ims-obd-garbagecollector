{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6d049b33-d929-4a17-b1fb-e0410123b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from dataloader import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f\"This notebook use {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8202466d-fa4b-495a-87d4-afe9c1130284",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "BATCH_SIZE = 8\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a7e2b-b93f-47b8-9b37-ed4c594b51c3",
   "metadata": {},
   "source": [
    "## DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fbcb69ff-6438-4e38-bb2f-4e6414e99681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=0.01s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'input/data'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b8334b-c6f7-4b97-925e-df3a4c32804b",
   "metadata": {},
   "source": [
    "### model load 함수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c5076043-27b3-46c8-9388-4624fedf87b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_model(model, device, saved_dir=\"model\", file_name=\"default.pt\"):\n",
    "    path = os.path.join(saved_dir, file_name)\n",
    "    checkpoint = torch.load(path, map_location=device)\n",
    "    model.load_state_dict(state_dict=checkpoint['model'])\n",
    "    print(\"model load success\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609bf3be-a8c0-4139-877b-78d04f4f9ab1",
   "metadata": {},
   "source": [
    "## Soft Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7adc5a31-eecf-44b6-b6da-c4bd8b571a35",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_saved_dir = \"model/save\"\n",
    "\n",
    "ensemble_list = [\n",
    "    {'modelPath':\"resnext50[ssl]_batch8_resize_iouCE_epoch14_score0.451.pt\",\n",
    "     'decoder':'DeepLabV3Plus',\n",
    "     'encoder':'resnext50_32x4d',\n",
    "     'encoder_weights':'ssl'\n",
    "    },\n",
    "    {'modelPath':\"resnext50[swsl]_batch8_resize_iouCE_epoch15_score0.448.pt\",\n",
    "     'decoder':'DeepLabV3Plus',\n",
    "     'encoder':'resnext50_32x4d',\n",
    "     'encoder_weights':'swsl'\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "654269f2-93d2-4bd1-8c36-d02155e65295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model load success\n",
      "step:105/105    End prediction\n",
      "model load success\n",
      "step:105/105    End prediction\n"
     ]
    }
   ],
   "source": [
    "### Ensemble ###\n",
    "\n",
    "oof_pred = None\n",
    "with torch.no_grad():\n",
    "    for mInfo in ensemble_list:\n",
    "        ## load Model                             (decoder를 여러개 사용하셨으면 조건문 추가하시면 됩니다.)\n",
    "        if (mInfo['decoder']=='DeepLabV3Plus'):\n",
    "            model = smp.DeepLabV3Plus(\n",
    "                encoder_name=mInfo['encoder'],\n",
    "                encoder_weights=mInfo['encoder_weights'],\n",
    "                classes=12\n",
    "            ).to(device)\n",
    "        else:\n",
    "            model=None\n",
    "            \n",
    "        load_model(model, device, saved_dir=model_saved_dir, file_name=mInfo['modelPath'])\n",
    "        \n",
    "        ## inference\n",
    "        model.eval()\n",
    "        preds_all = []\n",
    "        for step, imgs in enumerate(test_loader):\n",
    "            outs = model(imgs.to(device))\n",
    "            preds_all.extend(outs.detach().cpu().numpy())\n",
    "            print(f\"\\rstep:{step+1:3d}/{len(test_loader)}\", end='')\n",
    "        print(\"    End prediction\")\n",
    "        \n",
    "        if oof_pred is None:\n",
    "            oof_pred = np.array(preds_all) / len(ensemble_list)\n",
    "        else:\n",
    "            oof_pred += np.array(preds_all) / len(ensemble_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ee272326-8bff-4470-8eff-0e4ea06f6964",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label To string.. 837/837"
     ]
    }
   ],
   "source": [
    "### argmax & To string ###\n",
    "\n",
    "preds = []\n",
    "for i, img in enumerate(oof_pred):\n",
    "    #oms = np.argmax(np.expand_dims(img,axis=0), axis=1)\n",
    "    oms = np.argmax(img, axis=0)\n",
    "    oms = oms.flatten().astype(int)\n",
    "    pred_str = [str(p) for p in oms]\n",
    "    preds.append(' '.join(pred_str))\n",
    "    print(f\"\\rlabel To string.. {i+1:3d}/{len(oof_pred)}\", end='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d0285da4-d16e-4fc8-a831-6e62c55c2f40",
   "metadata": {},
   "outputs": [],
   "source": [
    "### csv 생성 ###\n",
    "submission = pd.read_csv('submission/sample_submission.csv')\n",
    "submission['PredictionString'] = preds\n",
    "submission.to_csv('submission/SoftEnsemble1.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750bc2c-7cda-4eb6-99e7-7c889f1da020",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "36dabbf6-87da-4e2e-a56b-1377c5a8f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-13-124-161-225.ap-northeast-2.compute.amazonaws.com:8000/api/v1/competition/28/presigned_url/?hyperparameters=%7B%22training%22%3A%7B%7D%2C%22inference%22%3A%7B%7D%7D&description=sm14_DL3P%2Bresnext50%5Bswsl%5D_epoch15_batch8_resize_iouCE+loss%3A+0.156++val_loss%3A+0.422++val_mIoU%3A0.448++val_mIoU2%3A0.522\n",
      "{\"url\":\"https://prod-aistages-private.s3.amazonaws.com/\",\"fields\":{\"key\":\"app/Competitions/000028/Users/00000303/Submissions/0011/output.csv\",\"x-amz-algorithm\":\"AWS4-HMAC-SHA256\",\"x-amz-credential\":\"AKIA45LU4MHUJ7WLDQVO/20210429/ap-northeast-2/s3/aws4_request\",\"x-amz-date\":\"20210429T100647Z\",\"policy\":\"eyJleHBpcmF0aW9uIjogIjIwMjEtMDQtMjlUMTE6MDY6NDdaIiwgImNvbmRpdGlvbnMiOiBbeyJidWNrZXQiOiAicHJvZC1haXN0YWdlcy1wcml2YXRlIn0sIHsia2V5IjogImFwcC9Db21wZXRpdGlvbnMvMDAwMDI4L1VzZXJzLzAwMDAwMzAzL1N1Ym1pc3Npb25zLzAwMTEvb3V0cHV0LmNzdiJ9LCB7IngtYW16LWFsZ29yaXRobSI6ICJBV1M0LUhNQUMtU0hBMjU2In0sIHsieC1hbXotY3JlZGVudGlhbCI6ICJBS0lBNDVMVTRNSFVKN1dMRFFWTy8yMDIxMDQyOS9hcC1ub3J0aGVhc3QtMi9zMy9hd3M0X3JlcXVlc3QifSwgeyJ4LWFtei1kYXRlIjogIjIwMjEwNDI5VDEwMDY0N1oifV19\",\"x-amz-signature\":\"c706096628c82dbb651d076dbf522f1df74125e54f3474bdd51bedc0ad333176\"},\"submission\":{\"id\":13203,\"phase\":\"Created\",\"type\":\"File\",\"local_id\":11,\"hyperparameters\":\"{\\\"training\\\": {}, \\\"inference\\\": {}}\",\"description\":\"sm14_DL3P+resnext50[swsl]_epoch15_batch8_resize_iouCE loss: 0.156  val_loss: 0.422  val_mIoU:0.448  val_mIoU2:0.522\",\"final\":false,\"created_at\":\"2021-04-29T19:06:47.884932+09:00\",\"updated_at\":\"2021-04-29T19:06:47.884964+09:00\",\"user\":303,\"competition\":28,\"image\":null}}\n"
     ]
    }
   ],
   "source": [
    "from utils import *\n",
    "\n",
    "file_name = \"SoftEnsemble1.csv\"\n",
    "description = \"SoftEnsemble1\"\n",
    "\n",
    "submit(\"submission/\"+file_name, description, key='my')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
