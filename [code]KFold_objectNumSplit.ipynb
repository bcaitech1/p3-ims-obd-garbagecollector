{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889bde91-3a0e-4daf-9f9f-3d79d4aeadc1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from utils import *\n",
    "from dataloader import *\n",
    "from loss import *\n",
    "from evaluate import *\n",
    "from scheduler import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f\"This notebook use {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ea9100-e351-4464-b72a-a3db4c838069",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "BATCH_SIZE = 8\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239afa51-9119-42d1-a8ce-ab6b81f03641",
   "metadata": {},
   "source": [
    "## Train Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0b92cc2-9159-4782-9481-e56d4d5ad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train(model, train_loader, val_loader, EPOCHS=21, save_model_name='fold_default'):\n",
    "    \n",
    "    # hyper parameters\n",
    "    LR_start = 2e-6\n",
    "    LR_max = 1e-4\n",
    "    accumulation_step = 1\n",
    "    print_every = 1\n",
    "    best_val_mIoU = 0.42\n",
    "    best_val_mIoU2 = 0.44\n",
    "    best_val_mIoU3 = 0.52\n",
    "\n",
    "    criterion = IoU_CE_Loss(iou_rate=0.4, weight=None)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR_start)\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, eta_max=LR_max, T_up=2, gamma=0.5)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch+=1\n",
    "        avg_loss = 0\n",
    "        batch_count = len(train_loader)\n",
    "\n",
    "        for step, (images, masks) in enumerate(train_loader):\n",
    "            start = time.time()\n",
    "            imgs, masks = images.to(device), masks.long().to(device)\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, masks)\n",
    "            loss.backward()\n",
    "\n",
    "            if (step+1)%accumulation_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            avg_loss += loss.item() / batch_count\n",
    "            print(f\"\\rEpoch:{epoch:3d}  step:{step:3d}/{batch_count-1}  time:{time.time() - start:.3f}  LR:{scheduler.get_lr()[0]:.6f}\", end='')\n",
    "\n",
    "        scheduler.step()\n",
    "        val_loss, val_mIoU, val_mIoU2, val_mIoU3 = validation3(model, val_loader, criterion, device)\n",
    "        print(f\"   loss:{avg_loss:.3f}  val_loss:{val_loss:.3f}  val_mIoU:{val_mIoU:.3f}  val_mIoU2:{val_mIoU2:.3f}  val_mIooU3:{val_mIoU3:.3f}  {epoch}\")\n",
    "        if best_val_mIoU < val_mIoU:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou1.pt')\n",
    "            best_val_mIoU = val_mIoU\n",
    "        elif best_val_mIoU2 < val_mIoU2:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou2.pt')\n",
    "            best_val_mIoU2 = val_mIoU2\n",
    "        elif best_val_mIoU3 < val_mIoU3:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou3.pt')\n",
    "            best_val_mIoU3 = val_mIoU3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcb6a9-11b6-498b-bb2b-31d4db74f417",
   "metadata": {},
   "source": [
    "## data load & transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "50fe5fa1-e3d8-49a1-a641-a30416252915",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dataset = np.load('input/data/img_all.npy', allow_pickle=True)\n",
    "anns_cnt = np.load('input/data/anns_cnt.npy')\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c44d7-35d8-43aa-8fcd-59240940c4ae",
   "metadata": {},
   "source": [
    "## 5-Fold train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "dd4f89ea-2ad5-4995-bc23-b14904b0d070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.14s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.12s)\n",
      "creating index...\n",
      "index created!\n",
      "--------------------------------------------------Fold1 Start training--------------------------------------------------\n",
      "Epoch:  1  step:326/326  time:0.276  LR:0.000002   loss:1.733  val_loss:1.553  val_mIoU:0.114  val_mIoU2:0.125  val_mIooU3:0.089  1\n",
      "Epoch:  2  step:326/326  time:0.275  LR:0.000051   loss:0.883  val_loss:0.678  val_mIoU:0.318  val_mIoU2:0.279  val_mIooU3:0.418  2\n",
      "Epoch:  3  step:326/326  time:0.278  LR:0.000100   loss:0.579  val_loss:0.616  val_mIoU:0.308  val_mIoU2:0.264  val_mIooU3:0.415  3\n",
      "Epoch:  4  step:326/326  time:0.278  LR:0.000099   loss:0.493  val_loss:0.599  val_mIoU:0.314  val_mIoU2:0.311  val_mIooU3:0.420  4\n",
      "Epoch:  5  step:326/326  time:0.275  LR:0.000097   loss:0.443  val_loss:0.553  val_mIoU:0.341  val_mIoU2:0.360  val_mIooU3:0.449  5\n",
      "Epoch:  6  step:326/326  time:0.280  LR:0.000093   loss:0.402  val_loss:0.520  val_mIoU:0.368  val_mIoU2:0.386  val_mIooU3:0.469  6\n",
      "Epoch:  7  step:326/326  time:0.276  LR:0.000089   loss:0.370  val_loss:0.535  val_mIoU:0.373  val_mIoU2:0.388  val_mIooU3:0.476  7\n",
      "Epoch:  8  step:326/326  time:0.277  LR:0.000082   loss:0.345  val_loss:0.545  val_mIoU:0.364  val_mIoU2:0.378  val_mIooU3:0.478  8\n",
      "Epoch:  9  step:326/326  time:0.276  LR:0.000076   loss:0.317  val_loss:0.506  val_mIoU:0.394  val_mIoU2:0.409  val_mIooU3:0.489  9\n",
      "Epoch: 10  step:326/326  time:0.278  LR:0.000068   loss:0.304  val_loss:0.532  val_mIoU:0.376  val_mIoU2:0.393  val_mIooU3:0.487  10\n",
      "Epoch: 11  step:326/326  time:0.280  LR:0.000060   loss:0.289  val_loss:0.489  val_mIoU:0.398  val_mIoU2:0.427  val_mIooU3:0.492  11\n",
      "Epoch: 12  step:326/326  time:0.275  LR:0.000051   loss:0.262  val_loss:0.484  val_mIoU:0.416  val_mIoU2:0.426  val_mIooU3:0.514  12\n",
      "Epoch: 13  step:326/326  time:0.278  LR:0.000042   loss:0.245  val_loss:0.470  val_mIoU:0.417  val_mIoU2:0.444  val_mIooU3:0.521  13\n",
      "Epoch: 14  step:326/326  time:0.278  LR:0.000034   loss:0.231  val_loss:0.472  val_mIoU:0.424  val_mIoU2:0.441  val_mIooU3:0.516  14\n",
      "Epoch: 15  step:326/326  time:0.277  LR:0.000027   loss:0.219  val_loss:0.473  val_mIoU:0.423  val_mIoU2:0.435  val_mIooU3:0.516  15\n",
      "Epoch: 16  step:326/326  time:0.274  LR:0.000020   loss:0.211  val_loss:0.466  val_mIoU:0.434  val_mIoU2:0.485  val_mIooU3:0.525  16\n",
      "Epoch: 17  step:326/326  time:0.279  LR:0.000013   loss:0.204  val_loss:0.451  val_mIoU:0.441  val_mIoU2:0.504  val_mIooU3:0.532  17\n",
      "Epoch: 18  step:326/326  time:0.274  LR:0.000009   loss:0.200  val_loss:0.467  val_mIoU:0.433  val_mIoU2:0.492  val_mIooU3:0.530  18\n",
      "Epoch: 19  step:326/326  time:0.283  LR:0.000005   loss:0.194  val_loss:0.462  val_mIoU:0.435  val_mIoU2:0.503  val_mIooU3:0.533  19\n",
      "Epoch: 20  step:326/326  time:0.276  LR:0.000003   loss:0.192  val_loss:0.460  val_mIoU:0.443  val_mIoU2:0.497  val_mIooU3:0.533  20\n",
      "Epoch: 21  step:326/326  time:0.277  LR:0.000002   loss:0.192  val_loss:0.460  val_mIoU:0.438  val_mIoU2:0.498  val_mIooU3:0.531  21\n",
      "--------------------------------------------------Fold1 Finish training--------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=5.11s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=3.74s)\n",
      "creating index...\n",
      "index created!\n",
      "--------------------------------------------------Fold2 Start training--------------------------------------------------\n",
      "Epoch:  1  step:326/326  time:0.281  LR:0.000002   loss:1.813  val_loss:1.620  val_mIoU:0.103  val_mIoU2:0.118  val_mIooU3:0.081  1\n",
      "Epoch:  2  step:326/326  time:0.279  LR:0.000051   loss:0.925  val_loss:0.627  val_mIoU:0.334  val_mIoU2:0.254  val_mIooU3:0.495  2\n",
      "Epoch:  3  step:326/326  time:0.278  LR:0.000100   loss:0.600  val_loss:0.505  val_mIoU:0.359  val_mIoU2:0.376  val_mIooU3:0.514  3\n",
      "Epoch:  4  step:326/326  time:0.275  LR:0.000099   loss:0.516  val_loss:0.475  val_mIoU:0.383  val_mIoU2:0.391  val_mIooU3:0.530  4\n",
      "Epoch:  5  step:326/326  time:0.278  LR:0.000097   loss:0.463  val_loss:0.470  val_mIoU:0.385  val_mIoU2:0.401  val_mIooU3:0.516  5\n",
      "Epoch:  6  step:326/326  time:0.277  LR:0.000093   loss:0.425  val_loss:0.441  val_mIoU:0.414  val_mIoU2:0.430  val_mIooU3:0.547  6\n",
      "Epoch:  7  step:326/326  time:0.277  LR:0.000089   loss:0.389  val_loss:0.430  val_mIoU:0.416  val_mIoU2:0.432  val_mIooU3:0.563  7\n",
      "Epoch:  8  step:326/326  time:0.274  LR:0.000082   loss:0.368  val_loss:0.436  val_mIoU:0.420  val_mIoU2:0.439  val_mIooU3:0.566  8\n",
      "Epoch:  9  step:326/326  time:0.276  LR:0.000076   loss:0.336  val_loss:0.403  val_mIoU:0.446  val_mIoU2:0.465  val_mIooU3:0.587  9\n",
      "Epoch: 10  step:326/326  time:0.277  LR:0.000068   loss:0.315  val_loss:0.407  val_mIoU:0.449  val_mIoU2:0.475  val_mIooU3:0.581  10\n",
      "Epoch: 11  step:326/326  time:0.276  LR:0.000060   loss:0.292  val_loss:0.397  val_mIoU:0.446  val_mIoU2:0.482  val_mIooU3:0.581  11\n",
      "Epoch: 12  step:326/326  time:0.274  LR:0.000051   loss:0.273  val_loss:0.391  val_mIoU:0.471  val_mIoU2:0.499  val_mIooU3:0.595  12\n",
      "Epoch: 13  step:326/326  time:0.273  LR:0.000042   loss:0.262  val_loss:0.395  val_mIoU:0.466  val_mIoU2:0.500  val_mIooU3:0.606  13\n",
      "Epoch: 14  step:326/326  time:0.274  LR:0.000034   loss:0.240  val_loss:0.387  val_mIoU:0.466  val_mIoU2:0.510  val_mIooU3:0.591  14\n",
      "Epoch: 15  step:326/326  time:0.274  LR:0.000027   loss:0.230  val_loss:0.381  val_mIoU:0.477  val_mIoU2:0.531  val_mIooU3:0.598  15\n",
      "Epoch: 16  step:326/326  time:0.276  LR:0.000020   loss:0.222  val_loss:0.375  val_mIoU:0.479  val_mIoU2:0.545  val_mIooU3:0.611  16\n",
      "Epoch: 17  step:326/326  time:0.275  LR:0.000013   loss:0.209  val_loss:0.379  val_mIoU:0.473  val_mIoU2:0.563  val_mIooU3:0.593  17\n",
      "Epoch: 18  step:326/326  time:0.275  LR:0.000009   loss:0.210  val_loss:0.377  val_mIoU:0.478  val_mIoU2:0.507  val_mIooU3:0.608  18\n",
      "Epoch: 19  step:326/326  time:0.278  LR:0.000005   loss:0.204  val_loss:0.377  val_mIoU:0.482  val_mIoU2:0.550  val_mIooU3:0.607  19\n",
      "Epoch: 20  step:326/326  time:0.280  LR:0.000003   loss:0.200  val_loss:0.376  val_mIoU:0.481  val_mIoU2:0.525  val_mIooU3:0.606  20\n",
      "Epoch: 21  step:326/326  time:0.275  LR:0.000002   loss:0.199  val_loss:0.371  val_mIoU:0.483  val_mIoU2:0.535  val_mIooU3:0.611  21\n",
      "--------------------------------------------------Fold2 Finish training--------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=5.18s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.65s)\n",
      "creating index...\n",
      "index created!\n",
      "--------------------------------------------------Fold3 Start training--------------------------------------------------\n",
      "Epoch:  1  step:326/326  time:0.560  LR:0.000002   loss:1.749  val_loss:1.548  val_mIoU:0.122  val_mIoU2:0.128  val_mIooU3:0.108  1\n",
      "Epoch:  2  step:326/326  time:0.562  LR:0.000051   loss:0.928  val_loss:0.549  val_mIoU:0.389  val_mIoU2:0.323  val_mIooU3:0.574  2\n",
      "Epoch:  3  step:326/326  time:0.564  LR:0.000100   loss:0.617  val_loss:0.446  val_mIoU:0.394  val_mIoU2:0.375  val_mIooU3:0.568  3\n",
      "Epoch:  4  step:326/326  time:0.569  LR:0.000099   loss:0.532  val_loss:0.400  val_mIoU:0.418  val_mIoU2:0.425  val_mIooU3:0.582  4\n",
      "Epoch:  5  step:326/326  time:0.549  LR:0.000097   loss:0.480  val_loss:0.371  val_mIoU:0.426  val_mIoU2:0.444  val_mIooU3:0.611  5\n",
      "Epoch:  6  step:326/326  time:0.563  LR:0.000093   loss:0.443  val_loss:0.363  val_mIoU:0.436  val_mIoU2:0.468  val_mIooU3:0.619  6\n",
      "Epoch:  7  step:326/326  time:0.555  LR:0.000089   loss:0.409  val_loss:0.359  val_mIoU:0.442  val_mIoU2:0.453  val_mIooU3:0.621  7\n",
      "Epoch:  8  step:326/326  time:0.462  LR:0.000082   loss:0.372  val_loss:0.420  val_mIoU:0.401  val_mIoU2:0.427  val_mIooU3:0.558  8\n",
      "Epoch:  9  step:326/326  time:0.443  LR:0.000076   loss:0.352  val_loss:0.342  val_mIoU:0.461  val_mIoU2:0.506  val_mIooU3:0.617  9\n",
      "Epoch: 10  step:326/326  time:0.468  LR:0.000068   loss:0.333  val_loss:0.345  val_mIoU:0.466  val_mIoU2:0.495  val_mIooU3:0.624  10\n",
      "Epoch: 11  step:326/326  time:0.466  LR:0.000060   loss:0.301  val_loss:0.329  val_mIoU:0.477  val_mIoU2:0.508  val_mIooU3:0.639  11\n",
      "Epoch: 12  step:326/326  time:0.470  LR:0.000051   loss:0.280  val_loss:0.329  val_mIoU:0.477  val_mIoU2:0.515  val_mIooU3:0.642  12\n",
      "Epoch: 13  step:326/326  time:0.461  LR:0.000042   loss:0.258  val_loss:0.319  val_mIoU:0.491  val_mIoU2:0.521  val_mIooU3:0.649  13\n",
      "Epoch: 14  step:326/326  time:0.482  LR:0.000034   loss:0.245  val_loss:0.319  val_mIoU:0.488  val_mIoU2:0.524  val_mIooU3:0.654  14\n",
      "Epoch: 15  step:326/326  time:0.491  LR:0.000027   loss:0.234  val_loss:0.322  val_mIoU:0.484  val_mIoU2:0.512  val_mIooU3:0.644  15\n",
      "Epoch: 16  step:326/326  time:0.453  LR:0.000020   loss:0.223  val_loss:0.315  val_mIoU:0.487  val_mIoU2:0.526  val_mIooU3:0.641  16\n",
      "Epoch: 17  step:326/326  time:0.474  LR:0.000013   loss:0.215  val_loss:0.313  val_mIoU:0.493  val_mIoU2:0.480  val_mIooU3:0.655  17\n",
      "Epoch: 18  step:326/326  time:0.466  LR:0.000009   loss:0.210  val_loss:0.320  val_mIoU:0.483  val_mIoU2:0.519  val_mIooU3:0.643  18\n",
      "Epoch: 19  step:326/326  time:0.484  LR:0.000005   loss:0.206  val_loss:0.316  val_mIoU:0.488  val_mIoU2:0.520  val_mIooU3:0.649  19\n",
      "Epoch: 20  step:326/326  time:0.492  LR:0.000003   loss:0.204  val_loss:0.312  val_mIoU:0.496  val_mIoU2:0.531  val_mIooU3:0.655  20\n",
      "Epoch: 21  step:326/326  time:0.461  LR:0.000002   loss:0.201  val_loss:0.312  val_mIoU:0.497  val_mIoU2:0.483  val_mIooU3:0.653  21\n",
      "--------------------------------------------------Fold3 Finish training--------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=4.10s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.77s)\n",
      "creating index...\n",
      "index created!\n",
      "--------------------------------------------------Fold4 Start training--------------------------------------------------\n",
      "Epoch:  1  step:326/326  time:0.280  LR:0.000002   loss:1.800  val_loss:1.572  val_mIoU:0.122  val_mIoU2:0.150  val_mIooU3:0.093  1\n",
      "Epoch:  2  step:326/326  time:0.293  LR:0.000051   loss:0.939  val_loss:0.623  val_mIoU:0.320  val_mIoU2:0.261  val_mIooU3:0.493  2\n",
      "Epoch:  3  step:326/326  time:0.277  LR:0.000100   loss:0.618  val_loss:0.489  val_mIoU:0.343  val_mIoU2:0.334  val_mIooU3:0.498  3\n",
      "Epoch:  4  step:326/326  time:0.567  LR:0.000099   loss:0.528  val_loss:0.434  val_mIoU:0.393  val_mIoU2:0.393  val_mIooU3:0.561  4\n",
      "Epoch:  5  step:326/326  time:0.562  LR:0.000097   loss:0.469  val_loss:0.404  val_mIoU:0.420  val_mIoU2:0.444  val_mIooU3:0.579  5\n",
      "Epoch:  6  step:326/326  time:0.551  LR:0.000093   loss:0.437  val_loss:0.399  val_mIoU:0.422  val_mIoU2:0.450  val_mIooU3:0.559  6\n",
      "Epoch:  7  step:326/326  time:0.559  LR:0.000089   loss:0.405  val_loss:0.394  val_mIoU:0.430  val_mIoU2:0.429  val_mIooU3:0.586  7\n",
      "Epoch:  8  step:326/326  time:0.561  LR:0.000082   loss:0.373  val_loss:0.402  val_mIoU:0.424  val_mIoU2:0.440  val_mIooU3:0.582  8\n",
      "Epoch:  9  step:326/326  time:0.538  LR:0.000076   loss:0.342  val_loss:0.379  val_mIoU:0.437  val_mIoU2:0.474  val_mIooU3:0.595  9\n",
      "Epoch: 10  step:326/326  time:0.275  LR:0.000068   loss:0.323  val_loss:0.386  val_mIoU:0.431  val_mIoU2:0.460  val_mIooU3:0.591  10\n",
      "Epoch: 11  step:326/326  time:0.277  LR:0.000060   loss:0.294  val_loss:0.381  val_mIoU:0.446  val_mIoU2:0.488  val_mIooU3:0.610  11\n",
      "Epoch: 12  step:326/326  time:0.276  LR:0.000051   loss:0.277  val_loss:0.371  val_mIoU:0.456  val_mIoU2:0.493  val_mIooU3:0.613  12\n",
      "Epoch: 13  step:326/326  time:0.276  LR:0.000042   loss:0.263  val_loss:0.374  val_mIoU:0.457  val_mIoU2:0.492  val_mIooU3:0.609  13\n",
      "Epoch: 14  step:326/326  time:0.275  LR:0.000034   loss:0.243  val_loss:0.360  val_mIoU:0.474  val_mIoU2:0.506  val_mIooU3:0.621  14\n",
      "Epoch: 15  step:326/326  time:0.276  LR:0.000027   loss:0.232  val_loss:0.373  val_mIoU:0.458  val_mIoU2:0.497  val_mIooU3:0.608  15\n",
      "Epoch: 16  step:326/326  time:0.276  LR:0.000020   loss:0.220  val_loss:0.365  val_mIoU:0.465  val_mIoU2:0.508  val_mIooU3:0.610  16\n",
      "Epoch: 17  step:326/326  time:0.278  LR:0.000013   loss:0.211  val_loss:0.362  val_mIoU:0.475  val_mIoU2:0.509  val_mIooU3:0.625  17\n",
      "Epoch: 18  step:326/326  time:0.273  LR:0.000009   loss:0.209  val_loss:0.365  val_mIoU:0.469  val_mIoU2:0.507  val_mIooU3:0.618  18\n",
      "Epoch: 19  step:326/326  time:0.277  LR:0.000005   loss:0.203  val_loss:0.361  val_mIoU:0.469  val_mIoU2:0.516  val_mIooU3:0.623  19\n",
      "Epoch: 20  step:326/326  time:0.273  LR:0.000003   loss:0.199  val_loss:0.361  val_mIoU:0.469  val_mIoU2:0.506  val_mIooU3:0.625  20\n",
      "Epoch: 21  step:326/326  time:0.274  LR:0.000002   loss:0.201  val_loss:0.357  val_mIoU:0.476  val_mIoU2:0.522  val_mIooU3:0.625  21\n",
      "--------------------------------------------------Fold4 Finish training--------------------------------------------------\n",
      "loading annotations into memory...\n",
      "Done (t=3.95s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=5.45s)\n",
      "creating index...\n",
      "index created!\n",
      "--------------------------------------------------Fold5 Start training--------------------------------------------------\n",
      "Epoch:  1  step:326/326  time:0.278  LR:0.000002   loss:1.615  val_loss:1.461  val_mIoU:0.122  val_mIoU2:0.146  val_mIooU3:0.124  1\n",
      "Epoch:  2  step:326/326  time:0.274  LR:0.000051   loss:0.835  val_loss:0.690  val_mIoU:0.296  val_mIoU2:0.262  val_mIooU3:0.417  2\n",
      "Epoch:  3  step:326/326  time:0.360  LR:0.000100   loss:0.555  val_loss:0.617  val_mIoU:0.313  val_mIoU2:0.305  val_mIooU3:0.413  3\n",
      "Epoch:  4  step:326/326  time:0.281  LR:0.000099   loss:0.476  val_loss:0.616  val_mIoU:0.306  val_mIoU2:0.322  val_mIooU3:0.426  4\n",
      "Epoch:  5  step:326/326  time:0.274  LR:0.000097   loss:0.434  val_loss:0.561  val_mIoU:0.356  val_mIoU2:0.375  val_mIooU3:0.462  5\n",
      "Epoch:  6  step:326/326  time:0.272  LR:0.000093   loss:0.386  val_loss:0.595  val_mIoU:0.330  val_mIoU2:0.355  val_mIooU3:0.450  6\n",
      "Epoch:  7  step:326/326  time:0.277  LR:0.000089   loss:0.358  val_loss:0.586  val_mIoU:0.340  val_mIoU2:0.370  val_mIooU3:0.462  7\n",
      "Epoch:  8  step:326/326  time:0.282  LR:0.000082   loss:0.343  val_loss:0.604  val_mIoU:0.337  val_mIoU2:0.353  val_mIooU3:0.474  8\n",
      "Epoch:  9  step:326/326  time:0.273  LR:0.000076   loss:0.319  val_loss:0.596  val_mIoU:0.339  val_mIoU2:0.368  val_mIooU3:0.460  9\n",
      "Epoch: 10  step:326/326  time:0.273  LR:0.000068   loss:0.301  val_loss:0.581  val_mIoU:0.363  val_mIoU2:0.366  val_mIooU3:0.493  10\n",
      "Epoch: 11  step:326/326  time:0.277  LR:0.000060   loss:0.276  val_loss:0.571  val_mIoU:0.364  val_mIoU2:0.389  val_mIooU3:0.502  11\n",
      "Epoch: 12  step:326/326  time:0.278  LR:0.000051   loss:0.252  val_loss:0.573  val_mIoU:0.371  val_mIoU2:0.392  val_mIooU3:0.507  12\n",
      "Epoch: 13  step:326/326  time:0.278  LR:0.000042   loss:0.240  val_loss:0.564  val_mIoU:0.376  val_mIoU2:0.399  val_mIooU3:0.500  13\n",
      "Epoch: 14  step:326/326  time:0.276  LR:0.000034   loss:0.236  val_loss:0.552  val_mIoU:0.376  val_mIoU2:0.395  val_mIooU3:0.492  14\n",
      "Epoch: 15  step:326/326  time:0.278  LR:0.000027   loss:0.218  val_loss:0.569  val_mIoU:0.381  val_mIoU2:0.401  val_mIooU3:0.507  15\n",
      "Epoch: 16  step:326/326  time:0.277  LR:0.000020   loss:0.210  val_loss:0.544  val_mIoU:0.393  val_mIoU2:0.430  val_mIooU3:0.512  16\n",
      "Epoch: 17  step:326/326  time:0.277  LR:0.000013   loss:0.204  val_loss:0.558  val_mIoU:0.392  val_mIoU2:0.413  val_mIooU3:0.512  17\n",
      "Epoch: 18  step:326/326  time:0.277  LR:0.000009   loss:0.198  val_loss:0.551  val_mIoU:0.386  val_mIoU2:0.421  val_mIooU3:0.514  18\n",
      "Epoch: 19  step:326/326  time:0.274  LR:0.000005   loss:0.198  val_loss:0.544  val_mIoU:0.395  val_mIoU2:0.425  val_mIooU3:0.516  19\n",
      "Epoch: 20  step:326/326  time:0.273  LR:0.000003   loss:0.193  val_loss:0.536  val_mIoU:0.398  val_mIoU2:0.429  val_mIooU3:0.517  20\n",
      "Epoch: 21  step:326/326  time:0.277  LR:0.000002   loss:0.190  val_loss:0.552  val_mIoU:0.385  val_mIoU2:0.418  val_mIooU3:0.516  21\n",
      "--------------------------------------------------Fold5 Finish training--------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_idx, valid_idx) in enumerate(skf.split(kfold_dataset, anns_cnt)):\n",
    "    \n",
    "    ## DataLoader ##\n",
    "    train_dataset = KFoldDataset(dataset=kfold_dataset[train_idx], mode='train', transform=train_transform)\n",
    "    val_dataset = KFoldDataset(dataset=kfold_dataset[valid_idx], mode='val', transform=train_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
    "    \n",
    "    ## model ##\n",
    "    model = smp.DeepLabV3Plus(\n",
    "        encoder_name='resnext50_32x4d',\n",
    "        encoder_weights='swsl',\n",
    "        classes=12\n",
    "    ).to(device)\n",
    "    \n",
    "    ## train ##\n",
    "    print(\"-\"*50 + f\" Fold{k+1} Start training \" + \"-\"*50)\n",
    "    fold_train(model, train_loader, val_loader, EPOCHS=21, save_model_name=f'[fold{k+1}]rxt50_resize_rotateFlip')\n",
    "    print(\"-\"*50 + f\" Fold{k+1} Finish training \" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68254598-3455-415c-a574-71fb31a6ffad",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "9d2f2289-ffc3-4633-83d4-ac2fc3a21db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_model(model, saved_dir=\"model\", file_name='[fold5]rxt50_resize_rotateFlip_epoch21.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
