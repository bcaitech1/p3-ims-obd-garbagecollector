{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "889bde91-3a0e-4daf-9f9f-3d79d4aeadc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import segmentation_models_pytorch as smp\n",
    "\n",
    "from utils import *\n",
    "from dataloader import *\n",
    "from loss import *\n",
    "from evaluate import *\n",
    "from scheduler import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f\"This notebook use {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "23ea9100-e351-4464-b72a-a3db4c838069",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "BATCH_SIZE = 8\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "239afa51-9119-42d1-a8ce-ab6b81f03641",
   "metadata": {},
   "source": [
    "## Train Function\n",
    "사용하는 train 코드로 바꿔주시면 됩니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b0b92cc2-9159-4782-9481-e56d4d5ad7e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fold_train(model, train_loader, val_loader, EPOCHS=21, save_model_name='fold_default'):\n",
    "    \n",
    "    # hyper parameters\n",
    "    LR_start = 2e-6\n",
    "    LR_max = 1e-4\n",
    "    accumulation_step = 1\n",
    "    print_every = 1\n",
    "    best_val_mIoU = 0.42\n",
    "    best_val_mIoU2 = 0.44\n",
    "    best_val_mIoU3 = 0.52\n",
    "\n",
    "    criterion = IoU_CE_Loss(iou_rate=0.4, weight=None)\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=LR_start)\n",
    "    scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, eta_max=LR_max, T_up=2, gamma=0.5)\n",
    "\n",
    "    for epoch in range(EPOCHS):\n",
    "        epoch+=1\n",
    "        avg_loss = 0\n",
    "        batch_count = len(train_loader)\n",
    "\n",
    "        for step, (images, masks) in enumerate(train_loader):\n",
    "            start = time.time()\n",
    "            imgs, masks = images.to(device), masks.long().to(device)\n",
    "\n",
    "            output = model(imgs)\n",
    "            loss = criterion(output, masks)\n",
    "            loss.backward()\n",
    "\n",
    "            if (step+1)%accumulation_step==0:\n",
    "                optimizer.step()\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "            avg_loss += loss.item() / batch_count\n",
    "            print(f\"\\rEpoch:{epoch:3d}  step:{step:3d}/{batch_count-1}  time:{time.time() - start:.3f}  LR:{scheduler.get_lr()[0]:.6f}\", end='')\n",
    "\n",
    "        scheduler.step()\n",
    "        val_loss, val_mIoU, val_mIoU2, val_mIoU3 = validation3(model, val_loader, criterion, device)\n",
    "        print(f\"   loss:{avg_loss:.3f}  val_loss:{val_loss:.3f}  val_mIoU:{val_mIoU:.3f}  val_mIoU2:{val_mIoU2:.3f}  val_mIooU3:{val_mIoU3:.3f}  {epoch}\")\n",
    "        if best_val_mIoU < val_mIoU:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou1.pt')\n",
    "            best_val_mIoU = val_mIoU\n",
    "        elif best_val_mIoU2 < val_mIoU2:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou2.pt')\n",
    "            best_val_mIoU2 = val_mIoU2\n",
    "        elif best_val_mIoU3 < val_mIoU3:\n",
    "            save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_miou3.pt')\n",
    "            best_val_mIoU3 = val_mIoU3"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18bef5e3-c243-42c8-84e3-c23668d134f6",
   "metadata": {},
   "source": [
    "## Dataset 클래스"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1241b6ea-8e1c-4479-961d-389b1cce26d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class PseudoKFoldDataset(Dataset):\n",
    "    \"\"\"COCO format\"\"\"\n",
    "    def __init__(self, dataset, transform = None):\n",
    "        super().__init__()\n",
    "        self.dataset = dataset\n",
    "        self.transform = transform\n",
    "        self.coco = COCO('input/data/train_all.json')\n",
    "        self.dataset_path = 'input/data/'\n",
    "        self.category_names = ['Backgroud', 'UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing']\n",
    "        \n",
    "    def __getitem__(self, index: int):\n",
    "        \n",
    "        ### load image ###\n",
    "        image_infos = self.dataset[index]\n",
    "        images = cv2.imread(self.dataset_path+image_infos['file_name'])\n",
    "        images = cv2.cvtColor(images, cv2.COLOR_BGR2RGB).astype(np.float32)\n",
    "        images /= 255.0\n",
    "        ### Pseudo mask ###\n",
    "        if image_infos['pseudo']:\n",
    "            masks = np.load(self.dataset_path+image_infos['mask_path'])\n",
    "            \n",
    "        ### Train mask ###\n",
    "        else:\n",
    "            ann_ids = self.coco.getAnnIds(imgIds=image_infos['id'])\n",
    "            anns = self.coco.loadAnns(ann_ids)\n",
    "            cat_ids = self.coco.getCatIds()\n",
    "            cats = self.coco.loadCats(cat_ids)\n",
    "            \n",
    "            masks = np.zeros((image_infos[\"height\"], image_infos[\"width\"]))\n",
    "            for i in range(len(anns)):\n",
    "                className = get_classname(anns[i]['category_id'], cats)\n",
    "                pixel_value = self.category_names.index(className)\n",
    "                masks = np.maximum(self.coco.annToMask(anns[i])*pixel_value, masks)            \n",
    "        masks = masks.astype(np.float32)\n",
    "\n",
    "        ###  augmentation ###\n",
    "        if self.transform is not None:\n",
    "            transformed = self.transform(image=images, mask=masks)\n",
    "            images = transformed[\"image\"]\n",
    "            masks = transformed[\"mask\"]\n",
    "        return images, masks\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9bcb6a9-11b6-498b-bb2b-31d4db74f417",
   "metadata": {},
   "source": [
    "## data load & transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "50fe5fa1-e3d8-49a1-a641-a30416252915",
   "metadata": {},
   "outputs": [],
   "source": [
    "kfold_dataset = np.load('input/data/pseudo_kfold_all.npy', allow_pickle=True)\n",
    "anns_cnt = np.load('input/data/pseudo_kfold_anns.npy')\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    A.RandomRotate90(),\n",
    "    A.HorizontalFlip(p=0.5),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    ToTensorV2()\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f0c44d7-35d8-43aa-8fcd-59240940c4ae",
   "metadata": {},
   "source": [
    "## 5-Fold train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd4f89ea-2ad5-4995-bc23-b14904b0d070",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=4.03s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=4.82s)\n",
      "creating index...\n",
      "index created!\n",
      "-------------------------------------------------- Fold1 Start training --------------------------------------------------\n",
      "Epoch:  1  step:368/402  time:0.274  LR:0.000002"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=5)\n",
    "for k, (train_idx, valid_idx) in enumerate(skf.split(kfold_dataset, anns_cnt)):\n",
    "    \n",
    "    ## DataLoader ##\n",
    "    train_dataset = PseudoKFoldDataset(dataset=kfold_dataset[train_idx], transform=train_transform)\n",
    "    val_dataset = KFoldDataset(dataset=kfold_dataset[valid_idx], transform=train_transform)\n",
    "    train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=1, drop_last=True)\n",
    "    val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=1)\n",
    "    \n",
    "    ## model ##\n",
    "    model = smp.DeepLabV3Plus(\n",
    "        encoder_name='resnext50_32x4d',\n",
    "        encoder_weights='swsl',\n",
    "        classes=12\n",
    "    ).to(device)\n",
    "    \n",
    "    ## train ##\n",
    "    print(\"-\"*50 + f\" Fold{k+1} Start training \" + \"-\"*50)\n",
    "    fold_train(model, train_loader, val_loader, EPOCHS=21, save_model_name=f'[fold{k+1}]rxt50_resize_rotateFlip')      ## train 함수 수정 필요 ##\n",
    "    print(\"-\"*50 + f\" Fold{k+1} Finish training \" + \"-\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c35466f2-078b-4871-ba2a-4adf510c6a0f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
