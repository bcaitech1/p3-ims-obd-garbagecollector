{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e08f9b6d-8703-4cac-93ae-97143806b1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import copy\n",
    "import os\n",
    "import os.path as osp\n",
    "import time\n",
    "import warnings\n",
    "\n",
    "import mmcv\n",
    "import torch\n",
    "from mmcv import Config, DictAction\n",
    "from mmcv.runner import get_dist_info, init_dist, load_checkpoint\n",
    "from mmcv.utils import get_git_hash\n",
    "\n",
    "from mmdet import __version__\n",
    "from mmdet.apis import set_random_seed, train_detector\n",
    "from mmdet.datasets import build_dataset\n",
    "from mmdet.models import build_detector\n",
    "from mmdet.utils import collect_env, get_root_logger\n",
    "import torch.distributed as dist\n",
    "os.environ['MASTER_ADDR'] = 'localhost'\n",
    "os.environ['MASTER_PORT'] = '6008'\n",
    "dist.init_process_group('gloo', rank=0, world_size=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3c1c23a0-964b-4a55-bfcb-dee0eef14bf4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classes = (\"UNKNOWN\", \"General trash\", \"Paper\", \"Paper pack\", \"Metal\", \"Glass\", \n",
    "           \"Plastic\", \"Styrofoam\", \"Plastic bag\", \"Battery\", \"Clothing\")\n",
    "# config file 들고오기\n",
    "cfg = Config.fromfile('./configs/swin/cascade_mask_rcnn_swin_base_patch4_window7_mstrain_480-800_giou_4conv1f_adamw_3x_coco.py')\n",
    "\n",
    "PREFIX = '../../input/data/'\n",
    "\n",
    "\n",
    "# dataset 바꾸기\n",
    "cfg.data.train.classes = classes\n",
    "cfg.data.train.img_prefix = PREFIX\n",
    "cfg.data.train.ann_file = PREFIX + 'train.json'\n",
    "# cfg.data.train.pipeline[2]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.val.classes = classes\n",
    "cfg.data.val.img_prefix = PREFIX\n",
    "cfg.data.val.ann_file = PREFIX + 'val.json'\n",
    "# cfg.data.val.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.test.classes = classes\n",
    "cfg.data.test.img_prefix = PREFIX\n",
    "cfg.data.test.ann_file = PREFIX + 'test.json'\n",
    "# cfg.data.test.pipeline[1]['img_scale'] = (512, 512)\n",
    "\n",
    "cfg.data.samples_per_gpu = 2\n",
    "\n",
    "cfg.seed=2020\n",
    "cfg.gpu_ids = [0]\n",
    "cfg.work_dir = './work_dirs/swin'\n",
    "\n",
    "for i in range(len(cfg.model.roi_head.bbox_head)):\n",
    "    cfg.model.roi_head.bbox_head[i].num_classes = 11\n",
    "cfg.model.roi_head.mask_head.num_classes = 11\n",
    "cfg.optimizer_config.grad_clip = dict(max_norm=35, norm_type=2)\n",
    "\n",
    "cfg.optimizer.lr = 1e-3\n",
    "cfg.checkpoint_config.interval = 5\n",
    "# cfg.model.backbone.use_checkpoint = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fceda541-c387-4790-a245-963a88e23507",
   "metadata": {},
   "outputs": [],
   "source": [
    "meta = dict()\n",
    "env_info_dict = collect_env()\n",
    "env_info = '\\n'.join([(f'{k}: {v}') for k, v in env_info_dict.items()])\n",
    "dash_line = '-' * 60 + '\\n'\n",
    "meta['env_info'] = env_info\n",
    "meta['config'] = cfg.pretty_text\n",
    "meta['seed'] = cfg.seed\n",
    "meta['exp_name'] = 'swin'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fb3ea165-0e49-41e6-9717-89cbc48c2031",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "key =  model\n",
      "{'type': 'CascadeRCNN', 'pretrained': None, 'backbone': {'type': 'SwinTransformer', 'embed_dim': 128, 'depths': [2, 2, 18, 2], 'num_heads': [4, 8, 16, 32], 'window_size': 7, 'mlp_ratio': 4.0, 'qkv_bias': True, 'qk_scale': None, 'drop_rate': 0.0, 'attn_drop_rate': 0.0, 'drop_path_rate': 0.3, 'ape': False, 'patch_norm': True, 'out_indices': (0, 1, 2, 3), 'use_checkpoint': False}, 'neck': {'type': 'FPN', 'in_channels': [128, 256, 512, 1024], 'out_channels': 256, 'num_outs': 5}, 'rpn_head': {'type': 'RPNHead', 'in_channels': 256, 'feat_channels': 256, 'anchor_generator': {'type': 'AnchorGenerator', 'scales': [8], 'ratios': [0.5, 1.0, 2.0], 'strides': [4, 8, 16, 32, 64]}, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [1.0, 1.0, 1.0, 1.0]}, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': True, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'SmoothL1Loss', 'beta': 0.1111111111111111, 'loss_weight': 1.0}}, 'roi_head': {'type': 'CascadeRoIHead', 'num_stages': 3, 'stage_loss_weights': [1, 0.5, 0.25], 'bbox_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 7, 'sampling_ratio': 0}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'bbox_head': [{'type': 'ConvFCBBoxHead', 'num_shared_convs': 4, 'num_shared_fcs': 1, 'in_channels': 256, 'conv_out_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 11, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.1, 0.1, 0.2, 0.2]}, 'reg_class_agnostic': False, 'reg_decoded_bbox': True, 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True}, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 10.0}}, {'type': 'ConvFCBBoxHead', 'num_shared_convs': 4, 'num_shared_fcs': 1, 'in_channels': 256, 'conv_out_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 11, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.05, 0.05, 0.1, 0.1]}, 'reg_class_agnostic': False, 'reg_decoded_bbox': True, 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True}, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 10.0}}, {'type': 'ConvFCBBoxHead', 'num_shared_convs': 4, 'num_shared_fcs': 1, 'in_channels': 256, 'conv_out_channels': 256, 'fc_out_channels': 1024, 'roi_feat_size': 7, 'num_classes': 11, 'bbox_coder': {'type': 'DeltaXYWHBBoxCoder', 'target_means': [0.0, 0.0, 0.0, 0.0], 'target_stds': [0.033, 0.033, 0.067, 0.067]}, 'reg_class_agnostic': False, 'reg_decoded_bbox': True, 'norm_cfg': {'type': 'SyncBN', 'requires_grad': True}, 'loss_cls': {'type': 'CrossEntropyLoss', 'use_sigmoid': False, 'loss_weight': 1.0}, 'loss_bbox': {'type': 'GIoULoss', 'loss_weight': 10.0}}], 'mask_roi_extractor': {'type': 'SingleRoIExtractor', 'roi_layer': {'type': 'RoIAlign', 'output_size': 14, 'sampling_ratio': 0}, 'out_channels': 256, 'featmap_strides': [4, 8, 16, 32]}, 'mask_head': {'type': 'FCNMaskHead', 'num_convs': 4, 'in_channels': 256, 'conv_out_channels': 256, 'num_classes': 11, 'loss_mask': {'type': 'CrossEntropyLoss', 'use_mask': True, 'loss_weight': 1.0}}}, 'train_cfg': {'rpn': {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.7, 'neg_iou_thr': 0.3, 'min_pos_iou': 0.3, 'match_low_quality': True, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 256, 'pos_fraction': 0.5, 'neg_pos_ub': -1, 'add_gt_as_proposals': False}, 'allowed_border': 0, 'pos_weight': -1, 'debug': False}, 'rpn_proposal': {'nms_across_levels': False, 'nms_pre': 2000, 'nms_post': 2000, 'max_per_img': 2000, 'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'min_bbox_size': 0}, 'rcnn': [{'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.5, 'neg_iou_thr': 0.5, 'min_pos_iou': 0.5, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'mask_size': 28, 'pos_weight': -1, 'debug': False}, {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.6, 'neg_iou_thr': 0.6, 'min_pos_iou': 0.6, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'mask_size': 28, 'pos_weight': -1, 'debug': False}, {'assigner': {'type': 'MaxIoUAssigner', 'pos_iou_thr': 0.7, 'neg_iou_thr': 0.7, 'min_pos_iou': 0.7, 'match_low_quality': False, 'ignore_iof_thr': -1}, 'sampler': {'type': 'RandomSampler', 'num': 512, 'pos_fraction': 0.25, 'neg_pos_ub': -1, 'add_gt_as_proposals': True}, 'mask_size': 28, 'pos_weight': -1, 'debug': False}]}, 'test_cfg': {'rpn': {'nms_across_levels': False, 'nms_pre': 1000, 'nms_post': 1000, 'max_per_img': 1000, 'nms': {'type': 'nms', 'iou_threshold': 0.7}, 'min_bbox_size': 0}, 'rcnn': {'score_thr': 0.05, 'nms': {'type': 'nms', 'iou_threshold': 0.5}, 'max_per_img': 100, 'mask_thr_binary': 0.5}}}\n",
      "key =  dataset_type\n",
      "CocoDataset\n",
      "key =  data_root\n",
      "data/coco/\n",
      "key =  img_norm_cfg\n",
      "{'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}\n",
      "key =  train_pipeline\n",
      "[{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}]\n",
      "key =  test_pipeline\n",
      "[{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}]\n",
      "key =  data\n",
      "{'samples_per_gpu': 2, 'workers_per_gpu': 2, 'train': {'type': 'CocoDataset', 'ann_file': '../../input/data/train.json', 'img_prefix': '../../input/data/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'LoadAnnotations', 'with_bbox': True, 'with_mask': True}, {'type': 'RandomFlip', 'flip_ratio': 0.5}, {'type': 'AutoAugment', 'policies': [[{'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}], [{'type': 'Resize', 'img_scale': [(400, 1333), (500, 1333), (600, 1333)], 'multiscale_mode': 'value', 'keep_ratio': True}, {'type': 'RandomCrop', 'crop_type': 'absolute_range', 'crop_size': (384, 600), 'allow_negative_crop': True}, {'type': 'Resize', 'img_scale': [(480, 1333), (512, 1333), (544, 1333), (576, 1333), (608, 1333), (640, 1333), (672, 1333), (704, 1333), (736, 1333), (768, 1333), (800, 1333)], 'multiscale_mode': 'value', 'override': True, 'keep_ratio': True}]]}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'DefaultFormatBundle'}, {'type': 'Collect', 'keys': ['img', 'gt_bboxes', 'gt_labels', 'gt_masks']}], 'classes': ('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')}, 'val': {'type': 'CocoDataset', 'ann_file': '../../input/data/val.json', 'img_prefix': '../../input/data/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}], 'classes': ('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')}, 'test': {'type': 'CocoDataset', 'ann_file': '../../input/data/test.json', 'img_prefix': '../../input/data/', 'pipeline': [{'type': 'LoadImageFromFile'}, {'type': 'MultiScaleFlipAug', 'img_scale': (1333, 800), 'flip': False, 'transforms': [{'type': 'Resize', 'keep_ratio': True}, {'type': 'RandomFlip'}, {'type': 'Normalize', 'mean': [123.675, 116.28, 103.53], 'std': [58.395, 57.12, 57.375], 'to_rgb': True}, {'type': 'Pad', 'size_divisor': 32}, {'type': 'ImageToTensor', 'keys': ['img']}, {'type': 'Collect', 'keys': ['img']}]}], 'classes': ('UNKNOWN', 'General trash', 'Paper', 'Paper pack', 'Metal', 'Glass', 'Plastic', 'Styrofoam', 'Plastic bag', 'Battery', 'Clothing')}}\n",
      "key =  evaluation\n",
      "{'metric': ['bbox', 'segm']}\n",
      "key =  optimizer\n",
      "{'type': 'AdamW', 'lr': 0.001, 'betas': (0.9, 0.999), 'weight_decay': 0.05, 'paramwise_cfg': {'custom_keys': {'absolute_pos_embed': {'decay_mult': 0.0}, 'relative_position_bias_table': {'decay_mult': 0.0}, 'norm': {'decay_mult': 0.0}}}}\n",
      "key =  optimizer_config\n",
      "{'grad_clip': {'max_norm': 35, 'norm_type': 2}}\n",
      "key =  lr_config\n",
      "{'policy': 'step', 'warmup': 'linear', 'warmup_iters': 500, 'warmup_ratio': 0.001, 'step': [27, 33]}\n",
      "key =  runner\n",
      "{'type': 'EpochBasedRunnerAmp', 'max_epochs': 36}\n",
      "key =  checkpoint_config\n",
      "{'interval': 5}\n",
      "key =  log_config\n",
      "{'interval': 50, 'hooks': [{'type': 'TextLoggerHook'}]}\n",
      "key =  custom_hooks\n",
      "[{'type': 'NumClassCheckHook'}]\n",
      "key =  dist_params\n",
      "{'backend': 'nccl'}\n",
      "key =  log_level\n",
      "INFO\n",
      "key =  load_from\n",
      "None\n",
      "key =  resume_from\n",
      "None\n",
      "key =  workflow\n",
      "[('train', 1)]\n",
      "key =  seed\n",
      "2020\n",
      "key =  gpu_ids\n",
      "[0]\n",
      "key =  work_dir\n",
      "./work_dirs/swin\n"
     ]
    }
   ],
   "source": [
    "for k in cfg.keys():\n",
    "    print(\"key = \",k)\n",
    "    print(cfg[k])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f6e6a582-83be-4ef8-88c3-d5529afa270c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "build\n",
      "loading annotations into memory...\n",
      "Done (t=3.63s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "datasets = [build_dataset(cfg.data.train)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "02f97826-3376-42e2-b24b-dc68f8c902cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def load_swin(cfg,ck_path):\n",
    "    # make temp_cfg\n",
    "    temp_cfg = copy.deepcopy(cfg)\n",
    "    \n",
    "    for i in range(len(temp_cfg.model.roi_head.bbox_head)):\n",
    "        temp_cfg.model.roi_head.bbox_head[i].num_classes = 80\n",
    "\n",
    "    # make original swin\n",
    "    pre_trained = build_detector(temp_cfg.model,train_cfg=None,\n",
    "        test_cfg=None)\n",
    "    load_checkpoint(pre_trained,ck_path, map_location='cpu')\n",
    "\n",
    "    model = build_detector(cfg.model,train_cfg=None,\n",
    "        test_cfg=None)\n",
    "\n",
    "    # make pretrained state dict\n",
    "    pretrained_dict = pre_trained.backbone.state_dict()\n",
    "    model_dict = model.backbone.state_dict()\n",
    "    pretrained_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "    model_dict.update(pretrained_dict) \n",
    "    del pre_trained\n",
    "    torch.cuda.empty_cache()\n",
    "    model.backbone.load_state_dict(model_dict)\n",
    "    return model\n",
    "\n",
    "def get_model(network,cfg,train=True):\n",
    "    repo_root = ''\n",
    "    \n",
    "    if network[-1] == 's':\n",
    "        ck_path = os.path.join(repo_root,'pretrained/cascade_mask_rcnn_swin_small_patch4_window7.pth')\n",
    "    elif network[-1] == 'b':\n",
    "        ck_path = os.path.join(repo_root,'pretrained/cascade_mask_rcnn_swin_base_patch4_window7.pth')\n",
    "    else:\n",
    "        ck_path = os.path.join(repo_root,'pretrained/cascade_mask_rcnn_swin_tiny_patch4_window7.pth')        \n",
    "    \n",
    "    if train:\n",
    "        return load_swin(cfg,ck_path)\n",
    "    else:\n",
    "        return make_swin_model(cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4702b19f-84d8-4e06-9fb1-9cd1c0e8eae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Use load_from_local loader\n",
      "The model and loaded state dict do not match exactly\n",
      "\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([11, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.0.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([11]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([11, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.1.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([11]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.weight: copying a param with shape torch.Size([80, 256, 1, 1]) from checkpoint, the shape in current model is torch.Size([11, 256, 1, 1]).\n",
      "size mismatch for roi_head.mask_head.2.conv_logits.bias: copying a param with shape torch.Size([80]) from checkpoint, the shape in current model is torch.Size([11]).\n"
     ]
    }
   ],
   "source": [
    "model = get_model('swin_b',cfg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3e6cb2dc-41c8-4547-86be-a948206e5cd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'policy': 'step',\n",
       " 'warmup': 'linear',\n",
       " 'warmup_iters': 500,\n",
       " 'warmup_ratio': 0.001,\n",
       " 'step': [27, 33]}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg.lr_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b9ae4c8-b354-4d27-984e-e988c9bf48ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "in\n",
      "build\n",
      "loading annotations into memory...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 09:46:08,960 - mmdet - INFO - Start running, host: root@28e81ee99bc4, work_dir: /opt/ml/code/Swin-Transformer-Object-Detection/work_dirs/swin\n",
      "2021-05-13 09:46:08,962 - mmdet - INFO - workflow: [('train', 1)], max: 36 epochs\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done (t=0.90s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2021-05-13 09:47:09,252 - mmdet - INFO - Epoch [1][50/1309]\tlr: 9.890e-05, eta: 15:45:52, time: 1.206, data_time: 0.064, memory: 13427, loss_rpn_cls: 0.4589, loss_rpn_bbox: 0.0631, s0.loss_cls: 0.7412, s0.acc: 88.2012, s0.loss_bbox: 0.1936, s0.loss_mask: 0.8713, s1.loss_cls: 0.3209, s1.acc: 88.3301, s1.loss_bbox: 0.0253, s1.loss_mask: 0.4995, s2.loss_cls: 0.1452, s2.acc: 90.6406, s2.loss_bbox: 0.0027, s2.loss_mask: 0.2546, loss: 3.5762, grad_norm: 11.4270\n",
      "2021-05-13 09:48:09,492 - mmdet - INFO - Epoch [1][100/1309]\tlr: 1.988e-04, eta: 15:44:33, time: 1.205, data_time: 0.019, memory: 13816, loss_rpn_cls: 0.1857, loss_rpn_bbox: 0.0654, s0.loss_cls: 0.4911, s0.acc: 87.5469, s0.loss_bbox: 0.4911, s0.loss_mask: 0.6400, s1.loss_cls: 0.1360, s1.acc: 94.4473, s1.loss_bbox: 0.0683, s1.loss_mask: 0.3237, s2.loss_cls: 0.0403, s2.acc: 97.2324, s2.loss_bbox: 0.0076, s2.loss_mask: 0.1646, loss: 2.6138, grad_norm: 6.3144\n",
      "2021-05-13 09:49:09,344 - mmdet - INFO - Epoch [1][150/1309]\tlr: 2.987e-04, eta: 15:41:24, time: 1.197, data_time: 0.017, memory: 13816, loss_rpn_cls: 0.1204, loss_rpn_bbox: 0.0497, s0.loss_cls: 0.4701, s0.acc: 88.8613, s0.loss_bbox: 0.4509, s0.loss_mask: 0.5776, s1.loss_cls: 0.1284, s1.acc: 94.9941, s1.loss_bbox: 0.0640, s1.loss_mask: 0.2849, s2.loss_cls: 0.0363, s2.acc: 97.5781, s2.loss_bbox: 0.0071, s2.loss_mask: 0.1472, loss: 2.3367, grad_norm: 6.5205\n",
      "2021-05-13 09:50:06,268 - mmdet - INFO - Epoch [1][200/1309]\tlr: 3.986e-04, eta: 15:27:53, time: 1.138, data_time: 0.018, memory: 13816, loss_rpn_cls: 0.1640, loss_rpn_bbox: 0.0769, s0.loss_cls: 0.4890, s0.acc: 88.2031, s0.loss_bbox: 0.4826, s0.loss_mask: 0.5772, s1.loss_cls: 0.1394, s1.acc: 94.2129, s1.loss_bbox: 0.0746, s1.loss_mask: 0.2869, s2.loss_cls: 0.0390, s2.acc: 97.2520, s2.loss_bbox: 0.0084, s2.loss_mask: 0.1452, loss: 2.4833, grad_norm: 6.8178\n",
      "2021-05-13 09:51:04,070 - mmdet - INFO - Epoch [1][250/1309]\tlr: 4.985e-04, eta: 15:22:08, time: 1.156, data_time: 0.017, memory: 13816, loss_rpn_cls: 0.1817, loss_rpn_bbox: 0.0696, s0.loss_cls: 0.4470, s0.acc: 89.1582, s0.loss_bbox: 0.4270, s0.loss_mask: 0.5562, s1.loss_cls: 0.1335, s1.acc: 94.0625, s1.loss_bbox: 0.0794, s1.loss_mask: 0.2676, s2.loss_cls: 0.0375, s2.acc: 97.1406, s2.loss_bbox: 0.0093, s2.loss_mask: 0.1347, loss: 2.3436, grad_norm: 6.9035\n",
      "2021-05-13 09:52:01,884 - mmdet - INFO - Epoch [1][300/1309]\tlr: 5.984e-04, eta: 15:18:01, time: 1.156, data_time: 0.015, memory: 13816, loss_rpn_cls: 0.1621, loss_rpn_bbox: 0.0671, s0.loss_cls: 0.4663, s0.acc: 89.5020, s0.loss_bbox: 0.4062, s0.loss_mask: 0.5706, s1.loss_cls: 0.1512, s1.acc: 93.5586, s1.loss_bbox: 0.0904, s1.loss_mask: 0.2761, s2.loss_cls: 0.0409, s2.acc: 96.9180, s2.loss_bbox: 0.0121, s2.loss_mask: 0.1328, loss: 2.3757, grad_norm: 6.4618\n",
      "2021-05-13 09:53:03,567 - mmdet - INFO - Epoch [1][350/1309]\tlr: 6.983e-04, eta: 15:23:25, time: 1.234, data_time: 0.020, memory: 13816, loss_rpn_cls: 0.1972, loss_rpn_bbox: 0.0798, s0.loss_cls: 0.5016, s0.acc: 88.3066, s0.loss_bbox: 0.4456, s0.loss_mask: 0.5975, s1.loss_cls: 0.1590, s1.acc: 93.0684, s1.loss_bbox: 0.0908, s1.loss_mask: 0.2786, s2.loss_cls: 0.0471, s2.acc: 96.4648, s2.loss_bbox: 0.0123, s2.loss_mask: 0.1386, loss: 2.5482, grad_norm: 5.6986\n",
      "2021-05-13 09:54:03,641 - mmdet - INFO - Epoch [1][400/1309]\tlr: 7.982e-04, eta: 15:24:05, time: 1.201, data_time: 0.020, memory: 13816, loss_rpn_cls: 0.2017, loss_rpn_bbox: 0.0790, s0.loss_cls: 0.4547, s0.acc: 89.6426, s0.loss_bbox: 0.3879, s0.loss_mask: 0.5898, s1.loss_cls: 0.1526, s1.acc: 93.2930, s1.loss_bbox: 0.0881, s1.loss_mask: 0.2805, s2.loss_cls: 0.0454, s2.acc: 96.5527, s2.loss_bbox: 0.0132, s2.loss_mask: 0.1395, loss: 2.4324, grad_norm: 5.3060\n",
      "2021-05-13 09:55:02,348 - mmdet - INFO - Epoch [1][450/1309]\tlr: 8.981e-04, eta: 15:22:01, time: 1.174, data_time: 0.016, memory: 14196, loss_rpn_cls: 0.2199, loss_rpn_bbox: 0.0781, s0.loss_cls: 0.4864, s0.acc: 88.8633, s0.loss_bbox: 0.4053, s0.loss_mask: 0.5575, s1.loss_cls: 0.1754, s1.acc: 92.1660, s1.loss_bbox: 0.1039, s1.loss_mask: 0.2607, s2.loss_cls: 0.0543, s2.acc: 95.7031, s2.loss_bbox: 0.0173, s2.loss_mask: 0.1278, loss: 2.4867, grad_norm: 5.7491\n",
      "2021-05-13 09:56:04,209 - mmdet - INFO - Epoch [1][500/1309]\tlr: 9.980e-04, eta: 15:25:04, time: 1.237, data_time: 0.021, memory: 14196, loss_rpn_cls: 0.2312, loss_rpn_bbox: 0.0960, s0.loss_cls: 0.5034, s0.acc: 87.7617, s0.loss_bbox: 0.4466, s0.loss_mask: 0.5390, s1.loss_cls: 0.1881, s1.acc: 91.0566, s1.loss_bbox: 0.1188, s1.loss_mask: 0.2545, s2.loss_cls: 0.0581, s2.acc: 95.1504, s2.loss_bbox: 0.0205, s2.loss_mask: 0.1217, loss: 2.5780, grad_norm: 6.0105\n",
      "2021-05-13 09:57:04,134 - mmdet - INFO - Epoch [1][550/1309]\tlr: 1.000e-03, eta: 15:24:38, time: 1.198, data_time: 0.019, memory: 14196, loss_rpn_cls: 0.2480, loss_rpn_bbox: 0.0857, s0.loss_cls: 0.4772, s0.acc: 89.4316, s0.loss_bbox: 0.3922, s0.loss_mask: 0.5817, s1.loss_cls: 0.1684, s1.acc: 93.2070, s1.loss_bbox: 0.0879, s1.loss_mask: 0.2723, s2.loss_cls: 0.0508, s2.acc: 96.3477, s2.loss_bbox: 0.0134, s2.loss_mask: 0.1344, loss: 2.5121, grad_norm: 6.4554\n",
      "2021-05-13 09:58:03,583 - mmdet - INFO - Epoch [1][600/1309]\tlr: 1.000e-03, eta: 15:23:30, time: 1.189, data_time: 0.019, memory: 14196, loss_rpn_cls: 0.2264, loss_rpn_bbox: 0.0682, s0.loss_cls: 0.4157, s0.acc: 91.0332, s0.loss_bbox: 0.3386, s0.loss_mask: 0.6171, s1.loss_cls: 0.1295, s1.acc: 95.0684, s1.loss_bbox: 0.0621, s1.loss_mask: 0.2972, s2.loss_cls: 0.0396, s2.acc: 97.4062, s2.loss_bbox: 0.0082, s2.loss_mask: 0.1429, loss: 2.3456, grad_norm: 4.8522\n",
      "2021-05-13 09:59:02,533 - mmdet - INFO - Epoch [1][650/1309]\tlr: 1.000e-03, eta: 15:21:47, time: 1.179, data_time: 0.016, memory: 14196, loss_rpn_cls: 0.1981, loss_rpn_bbox: 0.0701, s0.loss_cls: 0.4607, s0.acc: 88.8379, s0.loss_bbox: 0.4112, s0.loss_mask: 0.5808, s1.loss_cls: 0.1639, s1.acc: 92.6172, s1.loss_bbox: 0.0963, s1.loss_mask: 0.2748, s2.loss_cls: 0.0506, s2.acc: 96.1211, s2.loss_bbox: 0.0152, s2.loss_mask: 0.1332, loss: 2.4548, grad_norm: 4.6912\n",
      "2021-05-13 10:00:03,248 - mmdet - INFO - Epoch [1][700/1309]\tlr: 1.000e-03, eta: 15:22:08, time: 1.214, data_time: 0.019, memory: 14196, loss_rpn_cls: 0.2185, loss_rpn_bbox: 0.0817, s0.loss_cls: 0.4523, s0.acc: 90.0254, s0.loss_bbox: 0.3686, s0.loss_mask: 0.5574, s1.loss_cls: 0.1660, s1.acc: 93.0430, s1.loss_bbox: 0.0928, s1.loss_mask: 0.2582, s2.loss_cls: 0.0511, s2.acc: 96.1992, s2.loss_bbox: 0.0155, s2.loss_mask: 0.1261, loss: 2.3881, grad_norm: 5.8600\n",
      "2021-05-13 10:01:04,075 - mmdet - INFO - Epoch [1][750/1309]\tlr: 1.000e-03, eta: 15:22:25, time: 1.217, data_time: 0.019, memory: 14196, loss_rpn_cls: 0.1740, loss_rpn_bbox: 0.0557, s0.loss_cls: 0.4528, s0.acc: 89.3125, s0.loss_bbox: 0.3926, s0.loss_mask: 0.5602, s1.loss_cls: 0.1633, s1.acc: 92.7324, s1.loss_bbox: 0.0974, s1.loss_mask: 0.2584, s2.loss_cls: 0.0475, s2.acc: 96.3242, s2.loss_bbox: 0.0144, s2.loss_mask: 0.1272, loss: 2.3436, grad_norm: 4.8717\n"
     ]
    }
   ],
   "source": [
    "train_detector(\n",
    "        model,\n",
    "        datasets,\n",
    "        cfg,\n",
    "        distributed=False,\n",
    "        validate=True,\n",
    "        meta=meta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922066fa-3e40-4594-9dc4-7dc86838062b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
