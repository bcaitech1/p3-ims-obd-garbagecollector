{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "6d049b33-d929-4a17-b1fb-e0410123b79d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This notebook use cuda:0\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "from pycocotools.coco import COCO\n",
    "import cv2\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import albumentations as A\n",
    "from albumentations.pytorch import ToTensorV2\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from natsort import natsorted\n",
    "from torch.cuda.amp import GradScaler, autocast\n",
    "\n",
    "from utils import *\n",
    "from dataloader import *\n",
    "from loss import *\n",
    "from evaluate import *\n",
    "from scheduler import *\n",
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print (f\"This notebook use {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8202466d-fa4b-495a-87d4-afe9c1130284",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 77\n",
    "BATCH_SIZE = 8\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "np.random.seed(SEED)\n",
    "random.seed(SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff1a7e2b-b93f-47b8-9b37-ed4c594b51c3",
   "metadata": {},
   "source": [
    "## Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fbcb69ff-6438-4e38-bb2f-4e6414e99681",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading annotations into memory...\n",
      "Done (t=3.75s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.74s)\n",
      "creating index...\n",
      "index created!\n",
      "loading annotations into memory...\n",
      "Done (t=0.00s)\n",
      "creating index...\n",
      "index created!\n"
     ]
    }
   ],
   "source": [
    "dataset_path = 'input/data'\n",
    "train_path = dataset_path + '/train.json'\n",
    "val_path = dataset_path + '/val.json'\n",
    "test_path = dataset_path + '/test.json'\n",
    "\n",
    "train_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "test_transform = A.Compose([\n",
    "    A.Resize(256, 256),\n",
    "    ToTensorV2()\n",
    "])\n",
    "\n",
    "\n",
    "train_dataset = CustomDataLoader(data_dir=train_path, mode='train', transform=train_transform)\n",
    "val_dataset = CustomDataLoader(data_dir=val_path, mode='val', transform=test_transform)\n",
    "test_dataset = CustomDataLoader(data_dir=test_path, mode='test', transform=test_transform)\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4, drop_last=True)\n",
    "val_loader = torch.utils.data.DataLoader(dataset=val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = torch.utils.data.DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "995cdab9-9fc4-49c6-b250-0ebb288be5ef",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c0f37a92-49be-482a-a131-a4405d439ed0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "Total number of parameters: [26,152,284]\n",
      "--------------------------------------------------\n",
      "Total number of Conv layer : 67\n"
     ]
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "# from torchvision import models\n",
    "# model = models.segmentation.deeplabv3_resnet50(pretrained=True)\n",
    "# model.classifier[4] = nn.Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
    "# model.aux_classifier[4] = nn.Conv2d(256, 12, kernel_size=(1, 1), stride=(1, 1))\n",
    "# model.to(device)\n",
    "\n",
    "import segmentation_models_pytorch as smp\n",
    "model = smp.DeepLabV3Plus(\n",
    "    encoder_name='resnext50_32x4d',#'efficientnet-b4',\n",
    "    encoder_weights='imagenet', \n",
    "    classes=12\n",
    ").to(device)\n",
    "\n",
    "calculate_parameter(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "953324e6-e85f-4e76-b506-97a52bfdfc9e",
   "metadata": {},
   "source": [
    "## Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48f10047-de5a-46ed-b759-a15ed3d5c6df",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start training..\n",
      "Epoch:  1  step:326/326  time:0.472  LR:0.000002   loss: 1.724  val_loss: 1.571  val_mIoU:0.104\n",
      "Epoch:  2  step:326/326  time:0.470  LR:0.000051   loss: 0.930  val_loss: 0.639  val_mIoU:0.311\n",
      "Epoch:  3  step:326/326  time:0.471  LR:0.000100   loss: 0.584  val_loss: 0.531  val_mIoU:0.350\n",
      "Epoch:  4  step:326/326  time:0.470  LR:0.000099   loss: 0.451  val_loss: 0.469  val_mIoU:0.386\n",
      "Epoch:  5  step:326/326  time:0.463  LR:0.000097   loss: 0.374  val_loss: 0.483  val_mIoU:0.373\n",
      "Epoch:  6  step:326/326  time:0.466  LR:0.000093   loss: 0.329  val_loss: 0.493  val_mIoU:0.378\n",
      "Epoch:  7  step:326/326  time:0.468  LR:0.000089   loss: 0.298  val_loss: 0.442  val_mIoU:0.423\n",
      "Epoch:  8  step:326/326  time:0.467  LR:0.000082   loss: 0.261  val_loss: 0.437  val_mIoU:0.412\n",
      "Epoch:  9  step:326/326  time:0.470  LR:0.000076   loss: 0.239  val_loss: 0.457  val_mIoU:0.401\n",
      "Epoch: 10  step:326/326  time:0.470  LR:0.000068   loss: 0.217  val_loss: 0.436  val_mIoU:0.419\n",
      "Epoch: 11  step:326/326  time:0.475  LR:0.000060   loss: 0.204  val_loss: 0.428  val_mIoU:0.431\n",
      "Epoch: 12  step:326/326  time:0.467  LR:0.000051   loss: 0.188  val_loss: 0.441  val_mIoU:0.417\n",
      "Epoch: 13  step:326/326  time:0.464  LR:0.000042   loss: 0.178  val_loss: 0.438  val_mIoU:0.419\n",
      "Epoch: 14  step:326/326  time:0.465  LR:0.000034   loss: 0.171  val_loss: 0.438  val_mIoU:0.425\n",
      "Epoch: 15  step:326/326  time:0.467  LR:0.000027   loss: 0.163  val_loss: 0.436  val_mIoU:0.429\n",
      "Epoch: 16  step:326/326  time:0.465  LR:0.000020   loss: 0.152  val_loss: 0.440  val_mIoU:0.424\n",
      "Epoch: 17  step:326/326  time:0.468  LR:0.000013   loss: 0.149  val_loss: 0.439  val_mIoU:0.429\n",
      "Epoch: 18  step:326/326  time:0.466  LR:0.000009   loss: 0.143  val_loss: 0.441  val_mIoU:0.427\n",
      "Epoch: 19  step:326/326  time:0.467  LR:0.000005   loss: 0.144  val_loss: 0.443  val_mIoU:0.428\n",
      "Epoch: 20  step:326/326  time:0.469  LR:0.000003   loss: 0.141  val_loss: 0.442  val_mIoU:0.428\n",
      "Epoch: 21  step:326/326  time:0.467  LR:0.000002   loss: 0.144  val_loss: 0.439  val_mIoU:0.429\n",
      "Epoch: 22  step:326/326  time:0.471  LR:0.000026   loss: 0.146  val_loss: 0.444  val_mIoU:0.428\n",
      "Epoch: 23  step:326/326  time:0.467  LR:0.000050   loss: 0.177  val_loss: 0.476  val_mIoU:0.405\n",
      "Epoch: 24  step: 97/326  time:0.467  LR:0.000050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-a7ad6790e221>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0maccumulation_step\u001b[0m\u001b[0;34m==\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m             \u001b[0mscaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.7/site-packages/torch/cuda/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    318\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"No inf checks were recorded for this optimizer.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    319\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 320\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    321\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    322\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "save_model_name = f'resnext50_batch8_resize_iouCE'\n",
    "\n",
    "# hyper parameters\n",
    "EPOCHS = 60\n",
    "LR_start = 2e-6\n",
    "LR_max = 1e-4\n",
    "accumulation_step = 1\n",
    "print_every = 1\n",
    "best_val_mIoU = 0.40\n",
    "\n",
    "# loss\n",
    "scaler = GradScaler()\n",
    "#weights = get_class_weight(train_set['label'].tolist())\n",
    "#class_weights = torch.FloatTensor(weights).cuda()\n",
    "#criterion = LabelSmoothingLoss(classes=42, smoothing=0.2)\n",
    "\n",
    "criterion = IoU_CE_Loss(iou_rate=0.4, weight=None)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR_start)\n",
    "scheduler = CosineAnnealingWarmUpRestarts(optimizer, T_0=20, eta_max=LR_max, T_up=2, gamma=0.5)\n",
    "\n",
    "scaler = GradScaler()\n",
    "print(\"Start training..\")\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch+=1\n",
    "    avg_loss = 0\n",
    "    batch_count = len(train_loader)\n",
    "\n",
    "    for step, (images, masks) in enumerate(train_loader):\n",
    "        start = time.time()\n",
    "        images, masks = images.to(device), masks.long().to(device)\n",
    "        \n",
    "        with autocast():\n",
    "            output = model(images)\n",
    "            loss = criterion(output, masks)\n",
    "        scaler.scale(loss).backward()\n",
    "\n",
    "        if (step+1)%accumulation_step==0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "        avg_loss += loss.item() / batch_count\n",
    "        print(f\"\\rEpoch:{epoch:3d}  step:{step:3d}/{batch_count-1}  time:{time.time() - start:.3f}  LR:{scheduler.get_lr()[0]:.6f}\", end='')\n",
    "        \n",
    "    scheduler.step()\n",
    "    val_loss, val_mIoU = validation(model, val_loader, criterion, device)\n",
    "    print(f\"   loss: {avg_loss:.3f}  val_loss: {val_loss:.3f}  val_mIoU:{val_mIoU:.3f}\")\n",
    "    if best_val_mIoU < val_mIoU:\n",
    "        save_model(model, saved_dir=\"model\", file_name=save_model_name + f'_epoch{epoch}_score{val_mIoU:.3f}.pt')\n",
    "        best_val_mIoU = val_mIoU\n",
    "print(\"Finish training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c28d135-12ee-48b9-b71c-aec98106b5a7",
   "metadata": {},
   "source": [
    "## Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0618a00f-83bf-4d3e-9285-7e768b48f1d7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "load success\n"
     ]
    }
   ],
   "source": [
    "load_model(model, device, saved_dir=\"model\", file_name=\"resnext50_batch8_resize_iouCE_epoch11_score0.431.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "654269f2-93d2-4bd1-8c36-d02155e65295",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "step:105/105    End prediction.\n"
     ]
    }
   ],
   "source": [
    "size = 256\n",
    "transform = A.Compose([A.Resize(256, 256)])\n",
    "model.eval()\n",
    "\n",
    "preds_array = np.empty((0, size*size), dtype=np.long)\n",
    "with torch.no_grad():\n",
    "    for step, imgs in enumerate(test_loader):\n",
    "\n",
    "        # inference (512 x 512)\n",
    "        outs = model(imgs.to(device))\n",
    "        oms = torch.argmax(outs.squeeze(), dim=1).detach().cpu().numpy()\n",
    "        # resize (256 x 256)\n",
    "#         temp_mask = []\n",
    "#         for img, mask in zip(np.stack(imgs), oms):\n",
    "#             transformed = transform(image=img, mask=mask)\n",
    "#             mask = transformed['mask']\n",
    "#             temp_mask.append(mask)\n",
    "\n",
    "#         oms = np.array(temp_mask)\n",
    "\n",
    "        oms = oms.reshape([oms.shape[0], size*size]).astype(int)\n",
    "        preds_array = np.vstack((preds_array, oms))\n",
    "        \n",
    "        print(f\"\\rstep:{step+1:3d}/{len(test_loader)}\", end='')\n",
    "print(\"    End prediction.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d0285da4-d16e-4fc8-a831-6e62c55c2f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "To string.. 837/837"
     ]
    }
   ],
   "source": [
    "submission = pd.read_csv('submission/sample_submission.csv')\n",
    "\n",
    "preds=[]\n",
    "for i, pred in enumerate(preds_array):\n",
    "    pred_str = [str(p) for p in pred]\n",
    "    preds.append(' '.join(pred_str))\n",
    "    print(f\"\\rTo string.. {i+1:3d}/{len(preds_array)}\", end='')\n",
    "    \n",
    "submission['PredictionString'] = preds\n",
    "submission.to_csv('submission/sm9_DL3P+resnext50_epoch11_batch8_resize_iouCE.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2750bc2c-7cda-4eb6-99e7-7c889f1da020",
   "metadata": {},
   "source": [
    "## submit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "36dabbf6-87da-4e2e-a56b-1377c5a8f48d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "http://ec2-13-124-161-225.ap-northeast-2.compute.amazonaws.com:8000/api/v1/competition/28/presigned_url/?hyperparameters=%7B%22training%22%3A%7B%7D%2C%22inference%22%3A%7B%7D%7D&description=DL3P%2Bresnext50_epoch11_batch8_resize_iouCE+loss%3A+0.204++val_loss%3A+0.428++val_mIoU%3A0.431\n",
      "{\"url\":\"https://prod-aistages-private.s3.amazonaws.com/\",\"fields\":{\"key\":\"app/Competitions/000028/Users/00000085/Submissions/0004/output.csv\",\"x-amz-algorithm\":\"AWS4-HMAC-SHA256\",\"x-amz-credential\":\"AKIA45LU4MHUJ7WLDQVO/20210428/ap-northeast-2/s3/aws4_request\",\"x-amz-date\":\"20210428T142613Z\",\"policy\":\"eyJleHBpcmF0aW9uIjogIjIwMjEtMDQtMjhUMTU6MjY6MTNaIiwgImNvbmRpdGlvbnMiOiBbeyJidWNrZXQiOiAicHJvZC1haXN0YWdlcy1wcml2YXRlIn0sIHsia2V5IjogImFwcC9Db21wZXRpdGlvbnMvMDAwMDI4L1VzZXJzLzAwMDAwMDg1L1N1Ym1pc3Npb25zLzAwMDQvb3V0cHV0LmNzdiJ9LCB7IngtYW16LWFsZ29yaXRobSI6ICJBV1M0LUhNQUMtU0hBMjU2In0sIHsieC1hbXotY3JlZGVudGlhbCI6ICJBS0lBNDVMVTRNSFVKN1dMRFFWTy8yMDIxMDQyOC9hcC1ub3J0aGVhc3QtMi9zMy9hd3M0X3JlcXVlc3QifSwgeyJ4LWFtei1kYXRlIjogIjIwMjEwNDI4VDE0MjYxM1oifV19\",\"x-amz-signature\":\"35c8299fa6b6a3b5136168891ce2b26b0910a0bea715e2532f60e74d404c317d\"},\"submission\":{\"id\":12908,\"phase\":\"Created\",\"type\":\"File\",\"local_id\":4,\"hyperparameters\":\"{\\\"training\\\": {}, \\\"inference\\\": {}}\",\"description\":\"DL3P+resnext50_epoch11_batch8_resize_iouCE loss: 0.204  val_loss: 0.428  val_mIoU:0.431\",\"final\":false,\"created_at\":\"2021-04-28T23:26:13.363031+09:00\",\"updated_at\":\"2021-04-28T23:26:13.363065+09:00\",\"user\":85,\"competition\":28,\"image\":null}}\n"
     ]
    }
   ],
   "source": [
    "file_name = \"sm9_DL3P+resnext50_epoch11_batch8_resize_iouCE.csv\"\n",
    "description = \"DL3P+resnext50_epoch11_batch8_resize_iouCE loss: 0.204  val_loss: 0.428  val_mIoU:0.431\"\n",
    "\n",
    "submit(\"submission/\"+file_name, description, key='정훈님')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
